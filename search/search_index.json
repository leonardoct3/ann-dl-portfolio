{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Neural Networks &amp; Deep Learning Portfolio","text":"Academic Term <p>2025.1</p>"},{"location":"#author","title":"Author","text":"<p>Leonardo Teixeira Artificial Neural Networks and Deep Learning Course</p>"},{"location":"#portfolio-overview","title":"Portfolio Overview","text":"<p>This portfolio documents my journey through the Artificial Neural Networks and Deep Learning course, showcasing both theoretical understanding and practical implementation of neural network concepts.</p> <p>Portfolio Structure</p> <p>This portfolio is organized into Exercises and Projects. Each section demonstrates different aspects of neural network design, implementation, and analysis. Navigate through the sidebar to explore specific topics.</p>"},{"location":"#progress-tracker","title":"Progress Tracker","text":""},{"location":"#exercises","title":"Exercises","text":"<ul> <li> Exercise 1 - Data Analysis \u2705 Completed</li> <li>2D Class Separability Analysis</li> <li>Higher-Dimensional Non-linearity  </li> <li>Real-World Data Preprocessing</li> <li> Exercise 2 - Neural Network Fundamentals</li> <li> Exercise 3 - Training Optimization</li> <li> Exercise 4 - Advanced Architectures</li> </ul>"},{"location":"#projects","title":"Projects","text":"<ul> <li> Final Project - To be announced</li> </ul>"},{"location":"#learning-objectives","title":"Learning Objectives","text":"<p>Throughout this course, I aim to develop expertise in:</p> <ol> <li>Data Analysis &amp; Preprocessing</li> <li>Understanding class separability</li> <li>Feature engineering for neural networks</li> <li> <p>Handling real-world datasets</p> </li> <li> <p>Neural Network Fundamentals</p> </li> <li>Perceptrons vs Multi-Layer Perceptrons</li> <li>Activation functions and their properties</li> <li> <p>Forward and backward propagation</p> </li> <li> <p>Training &amp; Optimization</p> </li> <li>Loss functions and optimization algorithms</li> <li>Regularization techniques</li> <li> <p>Hyperparameter tuning</p> </li> <li> <p>Advanced Architectures</p> </li> <li>Convolutional Neural Networks (CNNs)</li> <li>Recurrent Neural Networks (RNNs)</li> <li>Modern architectures and techniques</li> </ol>"},{"location":"#technical-skills-demonstrated","title":"Technical Skills Demonstrated","text":""},{"location":"#programming-tools","title":"Programming &amp; Tools","text":"<ul> <li>Python: NumPy, Pandas, Matplotlib, Seaborn</li> <li>Machine Learning: Scikit-learn, TensorFlow/PyTorch</li> <li>Data Visualization: Statistical plots, PCA analysis</li> <li>Documentation: Markdown, MkDocs, Jupyter Notebooks</li> </ul>"},{"location":"#analytical-skills","title":"Analytical Skills","text":"<ul> <li>Statistical data analysis</li> <li>Dimensionality reduction techniques</li> <li>Class separability assessment</li> <li>Feature engineering strategies</li> </ul>"},{"location":"#portfolio-highlights","title":"Portfolio Highlights","text":""},{"location":"#exercise-1-data-analysis-mastery","title":"Exercise 1: Data Analysis Mastery","text":"<ul> <li>\u2705 Generated and analyzed 2D multi-class datasets</li> <li>\u2705 Explored linear vs nonlinear separability concepts</li> <li>\u2705 Applied PCA to 5D datasets for visualization</li> <li>\u2705 Preprocessed real-world Spaceship Titanic dataset</li> <li>\u2705 Optimized data for tanh activation functions</li> </ul> <p>Key Achievement: Demonstrated comprehensive understanding of how data characteristics influence neural network design decisions.</p>"},{"location":"#navigation-guide","title":"Navigation Guide","text":"<p>Use the sidebar to explore:</p> <ul> <li>Exercises: Detailed implementations and analyses</li> <li>Projects: Comprehensive applications of learned concepts  </li> <li>Documentation: Technical details about this portfolio</li> </ul> <p>Each exercise includes: - Problem statements and objectives - Step-by-step implementations - Visualizations and results - Key insights and learnings - Code examples with explanations</p>"},{"location":"#contact-collaboration","title":"Contact &amp; Collaboration","text":"<p>This portfolio represents my academic work in neural networks and deep learning. Feel free to explore the implementations and analyses documented here.</p> <p>GitHub Repository: ann-dl-portfolio</p>"},{"location":"#references","title":"References","text":"<p>Material for MkDocs</p>"},{"location":"exercises/data/main/","title":"Exercise 1 - Data Analysis","text":""},{"location":"exercises/data/main/#overview","title":"Overview","text":"<p>This exercise explores fundamental concepts in data analysis and neural network preparation through three distinct parts:</p> <ol> <li>2D Class Separability - Understanding linear vs nonlinear decision boundaries</li> <li>High-Dimensional Analysis - Exploring non-linearity in 5D space using PCA</li> <li>Real-World Data Preprocessing - Preparing Spaceship Titanic dataset for neural networks</li> </ol>"},{"location":"exercises/data/main/#1-class-separability-in-2d","title":"1) Class Separability in 2D","text":""},{"location":"exercises/data/main/#dataset-generation","title":"Dataset Generation","text":"<p>I generated a 2D dataset with four distinct classes, each following a normal distribution:</p> <ul> <li>Class 0 (Blue): Mean = [2,3], Standard Deviation = [0.8,2.5], 100 samples</li> <li>Class 1 (Orange): Mean = [5,6], Standard Deviation = [1.2,1.9], 100 samples  </li> <li>Class 2 (Green): Mean = [8,1], Standard Deviation = [0.9,0.9], 100 samples</li> <li>Class 3 (Red): Mean = [15,4], Standard Deviation = [0.5,2.0], 100 samples</li> </ul> <p>The dataset was generated using <code>numpy.random.normal()</code>. Each class has distinct characteristics designed to demonstrate different types of separability challenges.</p> <p>Dataset Generation Code</p> <pre><code>import numpy as np\nimport pandas as pd\n\n# Class 0 (Blue): Mean = [2,3], Std = [0.8,2.5]\nmu_x, mu_y = 2, 3\nstd_x, std_y = 0.8, 2.5\nn = 100\n\nX = np.random.normal(mu_x, std_x, n)\nY = np.random.normal(mu_y, std_y, n)\n\nfirst_class = pd.DataFrame({'X': X, 'Y': Y, 'Class': [0] * n})\n\n# Similar process for Classes 1, 2, and 3...\n# Class 1: Mean = [5,6], Std = [1.2,1.9]\n# Class 2: Mean = [8,1], Std = [0.9,0.9] \n# Class 3: Mean = [15,4], Std = [0.5,2.0]\n\n# Combine all classes\nsample = pd.concat([first_class, second_class, third_class, fourth_class], ignore_index=True)\n</code></pre>"},{"location":"exercises/data/main/#visualization-and-analysis","title":"Visualization and Analysis","text":"<p>Figure 1: Scatter plot showing four classes with clear color coding and proper axis labels. Each point represents a sample, with colors indicating class membership.</p> <p>Visualization Code</p> <pre><code>import matplotlib.pyplot as plt\n# Scatter plot for sample X and Y with title and legend\nfor label, group in sample.groupby('Class'):\n    plt.scatter(group['X'], group['Y'], label=f'Class {label}')\n\nplt.title('Scatter Plot of Sample Data')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.legend()\nplt.show()\n</code></pre>"},{"location":"exercises/data/main/#decision-boundaries","title":"Decision Boundaries","text":"<p>The dataset demonstrates different types of class separability that neural networks must handle:</p> <p></p> <p>Figure 2: Decision boundaries overlaid on the dataset, showing linear and nonlinear separation strategies.</p>"},{"location":"exercises/data/main/#class-separability-analysis","title":"Class Separability Analysis","text":""},{"location":"exercises/data/main/#class-3-red-linearly-separable","title":"Class 3 (Red) - Linearly Separable","text":"<ul> <li>Completely isolated with clear margin from other classes</li> <li>A simple linear boundary (vertical line at x \u2248 12) can achieve 100% separation</li> <li>Network Learning: A single perceptron could learn this boundary perfectly</li> </ul>"},{"location":"exercises/data/main/#classes-0-1-blue-orange-nonlinearly-separable","title":"Classes 0 &amp; 1 (Blue &amp; Orange) - Nonlinearly Separable","text":"<ul> <li>Significant overlap in feature space due to high variance</li> <li>Linear boundary would misclassify ~15-20% of samples</li> <li>Network Learning: Requires hidden layers to learn curved decision boundary that wraps around the overlapping region</li> </ul>"},{"location":"exercises/data/main/#class-2-green-moderately-separable","title":"Class 2 (Green) - Moderately Separable","text":"<ul> <li>Compact, low-variance cluster but positioned between other classes</li> <li>Requires elliptical/circular boundary for optimal separation</li> <li>Network Learning: Hidden layer neurons can learn radial basis-like boundaries</li> </ul>"},{"location":"exercises/data/main/#overall-complexity","title":"Overall Complexity","text":"<ul> <li>The dataset requires at least 3 distinct decision boundaries</li> <li>Linear classifier accuracy would be limited to ~75-80%</li> <li>Neural network with 2-3 hidden neurons could achieve &gt;95% accuracy</li> </ul>"},{"location":"exercises/data/main/#neural-network-implications","title":"Neural Network Implications","text":"<ul> <li>Perceptron - Can only handle linear separations (e.g., isolating Class 3)</li> <li>Multi-Layer Perceptron (MLP) - Required for nonlinear boundaries between overlapping classes</li> <li>Decision Complexity - Increases from Class 3 (linear) to Classes 0-2 (nonlinear)</li> </ul>"},{"location":"exercises/data/main/#2-non-linearity-in-higher-dimensions","title":"2) Non-Linearity in Higher Dimensions","text":""},{"location":"exercises/data/main/#5d-dataset-generation","title":"5D Dataset Generation","text":"<p>Created two classes in 5-dimensional space using multivariate normal distributions with specific covariance structures:</p>"},{"location":"exercises/data/main/#class-0-500-samples","title":"Class 0: 500 samples","text":"<ul> <li>Mean vector: <code>mu_0 = [0, 0, 0, 0, 0]</code></li> <li>Covariance matrix: Positive correlations between adjacent features   <pre><code>cov_0 = [[1.0, 0.5, 0.2, 0.1, 0.0],\n      [0.5, 1.0, 0.5, 0.2, 0.1],\n      [0.2, 0.5, 1.0, 0.5, 0.2],\n      [0.1, 0.2, 0.5, 1.0, 0.5],\n      [0.0, 0.1, 0.2, 0.5, 1.0]]\n</code></pre></li> </ul>"},{"location":"exercises/data/main/#class-1-500-samples","title":"Class 1: 500 samples","text":"<ul> <li>Mean vector: <code>mu_1 = [1.5, 1.5, 1.5, 1.5, 1.5]</code></li> <li>Covariance matrix: Mixed correlations creating complex structure   <pre><code>cov_1 = [[1.0, -0.3, 0.4, -0.2, 0.3],\n      [-0.3, 1.0, -0.2, 0.4, -0.1],\n      [0.4, -0.2, 1.0, -0.3, 0.2],\n      [-0.2, 0.4, -0.3, 1.0, -0.2],\n      [0.3, -0.1, 0.2, -0.2, 1.0]]\n</code></pre></li> </ul> <p>Both datasets were generated using <code>numpy.random.multivariate_normal()</code> with these exact parameters to ensure reproducible, realistic high-dimensional data.</p> <p>5D Dataset Generation Code</p> <pre><code>import numpy as np\nfrom sklearn.decomposition import PCA\n\n# Class 0: Mean = [0,0,0,0,0]\nmu_0 = np.zeros(5)\ncov_0 = [\n    [1.0, 0.8, 0.1, 0.0, 0.0],\n    [0.8, 1.0, 0.3, 0.0, 0.0],\n    [0.1, 0.3, 1.0, 0.5, 0.0],\n    [0.0, 0.0, 0.5, 1.0, 0.2],\n    [0.0, 0.0, 0.0, 0.2, 1.0]\n]\n\n# Class 1: Mean = [1.5,1.5,1.5,1.5,1.5]\nmu_1 = [1.5, 1.5, 1.5, 1.5, 1.5]\ncov_1 = [\n    [1.5, -0.7, 0.2, 0.0, 0.0],\n    [-0.7, 1.5, 0.4, 0.0, 0.0],\n    [0.2, 0.4, 1.5, 0.6, 0.0],\n    [0.0, 0.0, 0.6, 1.5, 0.3],\n    [0.0, 0.0, 0.0, 0.3, 1.5]\n]\n\n# Generate 500 samples for each class\nclass_0 = np.random.multivariate_normal(mu_0, cov_0, size=500)\nclass_1 = np.random.multivariate_normal(mu_1, cov_1, size=500)\n</code></pre>"},{"location":"exercises/data/main/#pca-analysis","title":"PCA Analysis","text":"<p>Applied Principal Component Analysis to project the 5D data into 2D for visualization and analysis:</p> <p></p> <p>Figure 3: 2D projection of 5D data using PCA. First two principal components capture the maximum variance while revealing class overlap.</p> <p></p> <p>Figure 4: Pairplot showing distributions along both principal components, with marginal histograms revealing the degree of class separation.</p> <p>PCA Implementation and Visualization</p> <pre><code>from sklearn.decomposition import PCA\nimport seaborn as sns\n\n# Apply PCA to reduce from 5D to 2D\nX = sample.drop('Class', axis=1)\nY = sample['Class']\n\npca = PCA(n_components=2)\npca.fit(X)\n\nprint(\"Explained variance:\")\nprint(pca.explained_variance_ratio_)\n\n# Transform data to 2D\nX_pca = pca.transform(X)\nnew_df = pd.DataFrame(X_pca, columns=['pc1', 'pc2'])\nnew_df['target'] = sample['Class']\n\n# Create pairplot with histograms\nsns.pairplot(\n    new_df, vars=['pc1', 'pc2'],\n    hue='target', diag_kind=\"hist\"\n)\nplt.show()\n</code></pre>"},{"location":"exercises/data/main/#analysis-of-the-2d-projection","title":"Analysis of the 2D Projection:","text":""},{"location":"exercises/data/main/#relationship-between-classes-a-and-b","title":"Relationship Between Classes A and B","text":"<ul> <li>Significant Overlap: The blue (Class 0) and orange (Class 1) points are heavily intermingled</li> <li>No Clear Boundary: There is no obvious linear separation between the two classes</li> <li>Complex Distribution: The classes form intertwined, curved patterns rather than distinct clusters</li> </ul>"},{"location":"exercises/data/main/#linear-separability-assessment","title":"Linear Separability Assessment","text":"<ul> <li>Not Linearly Separable: No single straight line could effectively separate the two classes</li> <li>High Misclassification: A linear classifier would incorrectly classify many points in the overlapping regions</li> <li>Curved Decision Boundary Needed: The optimal separation would require a complex, non-linear boundary</li> </ul>"},{"location":"exercises/data/main/#why-this-challenges-simple-linear-models","title":"Why This Challenges Simple Linear Models:","text":""},{"location":"exercises/data/main/#the-linear-model-problem","title":"The Linear Model Problem","text":"<p>A linear model can only create a single straight line decision boundary to separate the two classes. In this scenario with significant class overlap patterns, a linear classifier would misclassify many data points in the overlapping regions. Linear models lack the flexibility to adapt to the curved, complex boundaries needed for optimal separation.</p>"},{"location":"exercises/data/main/#why-multi-layer-neural-networks-are-needed","title":"Why Multi-Layer Neural Networks Are Needed","text":"<p>Multi-layer neural networks can handle this complex data because they have several key advantages:</p> <ul> <li>Flexible Decision Making: Unlike linear models that can only draw straight lines, neural networks can learn curved and complex boundaries that bend around the data</li> <li>Multiple Processing Layers: Each layer can transform the data in different ways, gradually building up a better understanding of how to separate the classes</li> <li>Learning from Examples: The network automatically figures out the best way to combine the original measurements to make accurate predictions</li> <li>Pattern Recognition: It can discover which combinations of the original features work best together to tell the classes apart</li> </ul> <p>This visualization demonstrates exactly why deep learning models excel at classification tasks - they can handle the complex, non-linear relationships that exist in high-dimensional data that simple linear models cannot capture.</p>"},{"location":"exercises/data/main/#3-real-world-data-preprocessing","title":"3) Real-World Data Preprocessing","text":""},{"location":"exercises/data/main/#spaceship-titanic-dataset","title":"Spaceship Titanic Dataset","text":""},{"location":"exercises/data/main/#dataset-description","title":"Dataset Description","text":"<ul> <li>Source: Kaggle Spaceship Titanic competition dataset</li> <li>Objective: Predict the <code>Transported</code> column (binary classification - whether passengers were transported to another dimension)</li> <li>Features: Mix of numerical, categorical, and text-based features</li> </ul>"},{"location":"exercises/data/main/#feature-types-identification","title":"Feature Types Identification","text":"<ul> <li>Numerical Features: <code>Age</code>, <code>RoomService</code>, <code>FoodCourt</code>, <code>ShoppingMall</code>, <code>Spa</code>, <code>VRDeck</code></li> <li>Categorical Features: <code>HomePlanet</code>, <code>CryoSleep</code>, <code>Destination</code>, <code>VIP</code></li> <li>Text/Identifier Features: <code>PassengerId</code>, <code>Name</code>, <code>Cabin</code></li> </ul> Data Exploration Code <pre><code>import pandas as pd\n\n# Load the dataset\ntrain = pd.read_csv('./data/train.csv')\ntest = pd.read_csv('./data/test.csv')\n\n# Explore data types and structure\nprint(\"Data types:\")\nprint(train.dtypes)\n\nprint(\"\\nBasic statistics:\")\nprint(train.describe())\n\nprint(\"\\nMissing values:\")\nprint(train.isnull().sum())\n</code></pre>"},{"location":"exercises/data/main/#missing-value-investigation","title":"Missing Value Investigation","text":"<p>The dataset contains missing values across several columns, requiring careful handling before neural network training. <pre><code>Missing values:\nPassengerId       0\nHomePlanet      201\nCryoSleep       217\nCabin           199\nDestination     182\nAge             179\nVIP             203\nRoomService     181\nFoodCourt       183\nShoppingMall    208\nSpa             183\nVRDeck          188\nName            200\nTransported       0\n</code></pre></p>"},{"location":"exercises/data/main/#preprocessing-implementation","title":"Preprocessing Implementation","text":"<p>Based on the provided preprocessing function, the following steps were implemented:</p>"},{"location":"exercises/data/main/#1-feature-engineering","title":"1. Feature Engineering","text":"<ul> <li>Cabin Parsing: Extracted <code>Deck</code>, <code>Num</code>, and <code>Side</code> from the cabin string (format: \"Deck/Num/Side\")</li> <li>Justification: The cabin information contains spatial patterns that could be predictive of passenger transportation</li> </ul>"},{"location":"exercises/data/main/#2-missing-value-handling-strategy","title":"2. Missing Value Handling Strategy","text":"<ul> <li>Numerical Features: Median imputation for <code>Age</code>, <code>RoomService</code>, <code>FoodCourt</code>, <code>ShoppingMall</code>, <code>Spa</code>, <code>VRDeck</code></li> <li>Categorical Features: \"Unknown\" category for missing values in <code>HomePlanet</code>, <code>Destination</code>, <code>Deck</code>, <code>Side</code></li> <li>Binary Features: Mode imputation for <code>CryoSleep</code> and <code>VIP</code></li> <li>Justification: Median imputation is robust to outliers and preserves the distribution of numerical data, while categorical imputation with \"Unknown\" maintains the categorical nature without bias.</li> </ul>"},{"location":"exercises/data/main/#3-categorical-encoding","title":"3. Categorical Encoding","text":"<ul> <li>One-Hot Encoding: Applied to <code>HomePlanet</code>, <code>Destination</code>, <code>Deck</code>, <code>Side</code></li> <li>Binary Mapping: Converted <code>CryoSleep</code> and <code>VIP</code> to {0, 1}</li> <li>Justification: Neural networks require numerical inputs; one-hot encoding preserves categorical independence without imposing ordinal relationships</li> </ul>"},{"location":"exercises/data/main/#4-feature-scaling-for-tanh-activation","title":"4. Feature Scaling for Tanh Activation","text":"<ul> <li>Standardization (Z-score): Applied to all numerical features using <code>StandardScaler</code></li> <li>Formula: <code>z = (x - \u03bc) / \u03c3</code> resulting in mean=0, standard deviation=1</li> <li>Justification: Tanh activation function operates optimally with inputs centered around zero. Standardization prevents gradient vanishing and ensures stable training.</li> </ul> <p>Complete Preprocessing Code Implementation</p> <pre><code>from sklearn.preprocessing import StandardScaler\n\ndef preprocess(df):\n    df = df.copy()\n\n    # Num\u00e9ricas\n    num_cols = [\"Age\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]\n    for c in num_cols:\n        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n        df[c].fillna(df[c].median(), inplace=True)\n\n    # Parsing de \"Cabin\" \n    cabin_parts = df[\"Cabin\"].astype(\"string\").str.split(\"/\", n=2, expand=True)\n    df[\"Deck\"] = cabin_parts[0]\n    df[\"Num\"]  = pd.to_numeric(cabin_parts[1], errors=\"coerce\")\n    df[\"Side\"] = cabin_parts[2]\n\n    # Muda tipo de \"Num\"\n    df[\"Num\"].fillna(df[\"Num\"].median(), inplace=True)\n\n    # Categ\u00f3ricas\n    cat_cols = [\"HomePlanet\", \"Destination\", \"Deck\", \"Side\"]\n    for c in cat_cols:\n        df[c] = df[c].astype(\"string\").fillna(\"Unknown\")\n\n    # Bin\u00e1rios ou Booleanos\n    bin_map = {True: 1, False: 0, \"True\": 1, \"False\": 0, \"true\": 1, \"false\": 0}\n    for b in [\"CryoSleep\", \"VIP\"]:\n        df[b] = df[b].map(bin_map)\n        # Se algum ainda n\u00e3o estiver preenchido, insere a Moda\n        if df[b].isna().any():\n            mode_val = df[b].mode().iloc[0] if not df[b].mode().empty else 0\n            df[b].fillna(mode_val, inplace=True)\n\n    # Drop das features que n\u00e3o ser\u00e3o utilizadas\n    drop_cols = [\"PassengerId\", \"Name\", \"Cabin\"]\n    existing_drop = [c for c in drop_cols if c in df.columns]\n    df.drop(columns=existing_drop, inplace=True)\n\n    # One-hot encode das Categ\u00f3ricas \n    X_cat = pd.get_dummies(df[cat_cols], drop_first=False, dtype=int)\n\n    # Todas as Num\u00e9ricas\n    num_all = num_cols + [\"Num\"]\n    X_num_raw = df[num_all].copy()\n\n    # Uso do Scaler pras Num\u00e9ricas\n    scaler = StandardScaler()\n    X_num = pd.DataFrame(\n        scaler.fit_transform(X_num_raw),\n        columns=num_all,\n        index=df.index\n    )\n\n    # Todas as Bin\u00e1rias\n    X_bin = df[[\"CryoSleep\", \"VIP\"]].astype(int)\n\n    # Junta tudo\n    X = pd.concat([X_num, X_bin, X_cat], axis=1)\n\n    # Retorna os dados preprocessados\n    return X\n\n# Aplica preprocessing\nX = preprocess(train)\n</code></pre>"},{"location":"exercises/data/main/#visualization-of-preprocessing-impact","title":"Visualization of Preprocessing Impact","text":"<p>Figure 5: Before and after comparison showing the effect of standardization on numerical features. The histograms demonstrate how standardization transforms the original feature distributions to have mean=0 and standard deviation=1, making them suitable for tanh activation function.</p> <p>Before/After Visualization Code</p> <pre><code># Histograms for Age and FoodCourt before scaling\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\ntrain['Age'].hist(ax=axes[0], bins=30, color='skyblue', alpha=0.7)\naxes[0].set_title('Age (Before Scaling)')\naxes[0].set_xlabel('Age')\naxes[0].set_ylabel('Frequency')\n\ntrain['FoodCourt'].hist(ax=axes[1], bins=30, color='orange', alpha=0.7)\naxes[1].set_title('FoodCourt (Before Scaling)')\naxes[1].set_xlabel('FoodCourt')\naxes[1].set_ylabel('Frequency')\nplt.tight_layout()\nplt.show()\n\n# Histograms for Age and FoodCourt after scaling\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\nX['Age'].hist(ax=axes[0], bins=30, color='skyblue', alpha=0.7)\naxes[0].set_title('Age (After Scaling)')\nX['FoodCourt'].hist(ax=axes[1], bins=30, color='orange', alpha=0.7)\naxes[1].set_title('FoodCourt (After Scaling)')\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"exercises/data/main/#why-this-preprocessing-is-essential-for-neural-networks","title":"Why This Preprocessing is Essential for Neural Networks:","text":""},{"location":"exercises/data/main/#tanh-activation-function-requirements","title":"Tanh Activation Function Requirements","text":"<ul> <li>Input Range: Tanh produces outputs in [-1, 1] and works best with standardized inputs</li> <li>Gradient Stability: Standardized features prevent gradient vanishing/exploding during backpropagation</li> <li>Training Efficiency: Features on similar scales converge faster during gradient descent</li> </ul>"},{"location":"exercises/data/main/#data-quality-for-neural-networks","title":"Data Quality for Neural Networks","text":"<ul> <li>No Missing Values: Complete dataset ensures consistent batch processing</li> <li>Numerical Consistency: All features converted to appropriate numerical format</li> <li>Categorical Handling: One-hot encoding creates binary features that neural networks can interpret effectively</li> </ul>"},{"location":"projects/classification/main/","title":"Project 1 - Classification","text":"<p>Aqui vai toda a documenta\u00e7\u00e3o do projeto, incluindo o que j\u00e1 foi feito e o que falta fazer.</p>"},{"location":"thisdocumentation/main/","title":"Documentation","text":""},{"location":"thisdocumentation/main/#pre-requisitos","title":"Pr\u00e9-requisitos","text":"<p>Antes de come\u00e7ar, certifique-se de que voc\u00ea possui os seguintes pr\u00e9-requisitos instalados em seu sistema:</p> <ul> <li>Git: Para clonar o reposit\u00f3rio.</li> </ul>"},{"location":"thisdocumentation/main/#instalando-o-python","title":"Instalando o Python","text":"LinuxmacOSWindows <p>Instale o Python 3.8 ou superior.</p> <pre><code>sudo apt install python3 python3-venv python3-pip\npython3 --version\n</code></pre> <p>Instale o Python 3.8 ou superior.</p> <pre><code>brew install python\npython3 --version\n</code></pre> <p>Instale o Python 3.13 ou superior. Baixe o instalador do site oficial do Python (https://www.python.org/downloads/) e execute-o. Certifique-se de marcar a op\u00e7\u00e3o \"Add Python to PATH\" durante a instala\u00e7\u00e3o.</p> <pre><code>python --version\n</code></pre>"},{"location":"thisdocumentation/main/#usage","title":"Usage","text":"<p>Para utilizar o c\u00f3digo deste reposit\u00f3rio, siga as instru\u00e7\u00f5es a seguir:</p> <p>Clone ou fork este reposit\u00f3rio:</p> <pre><code>git clone &lt;URL_DO_REPOSITORIO&gt;\n</code></pre> <p>Crie um ambiente virtual do Python:</p> Linux/macOSWindows <pre><code>python3 -m venv env\n</code></pre> <pre><code>python -m venv env\n</code></pre> <p>Ative o ambiente virtual (voc\u00ea deve fazer isso sempre que for executar algum script deste reposit\u00f3rio):</p> Linux/macOSWindows <pre><code>source ./env/bin/activate\n</code></pre> <pre><code>.\\env\\Scripts\\activate\n</code></pre> <p>Instale as depend\u00eancias com:</p> Linux/macOSWindows <pre><code>python3 -m pip install -r requirements.txt --upgrade\n</code></pre> <pre><code>python -m pip install -r requirements.txt --upgrade\n</code></pre>"},{"location":"thisdocumentation/main/#deployment","title":"Deployment","text":"<p>O material utiliza o mkdocs para gerar a documenta\u00e7\u00e3o. Para visualizar a documenta\u00e7\u00e3o, execute o comando:</p> <pre><code>mkdocs serve -o\n</code></pre> <p>Para subir ao GitHub Pages, execute o comando:</p> <pre><code>mkdocs gh-deploy\n</code></pre> <p>Esse reposit\u00f3rio possui um workflow do GitHub Actions que executa o comando <code>mkdocs gh-deploy</code> sempre que houver um push na branch <code>main</code>. Assim, n\u00e3o \u00e9 necess\u00e1rio executar esse comando manualmente. Toda vez que voc\u00ea fizer um push na branch <code>main</code>, a documenta\u00e7\u00e3o ser\u00e1 atualizada automaticamente no GitHub Pages.</p> <p>Aviso 1</p> <p>Para que o github actions funcione corretamente, \u00e9 necess\u00e1rio que o reposit\u00f3rio esteja configurado para que o bot <code>github-actions[bot]</code> tenha permiss\u00e3o de escrita. Voc\u00ea pode verificar isso nas configura\u00e7\u00f5es do reposit\u00f3rio, na se\u00e7\u00e3o \"Actions\" e depois em \"General\". Certifique-se de que a op\u00e7\u00e3o \"Workflow permissions\" esteja definida como \"Read and write permissions\".</p> <p></p> <p>Aviso 2</p> <p>Depois de publicar, caso n\u00e3o consiga acessar a p\u00e1gina, verifique se o github pages est\u00e1 configurado corretamente. V\u00e1 at\u00e9 as configura\u00e7\u00f5es do reposit\u00f3rio, na se\u00e7\u00e3o \"Pages\" e verifique se a branch <code>gh-pages</code> est\u00e1 selecionada como fonte. Se n\u00e3o estiver, selecione-a e salve as altera\u00e7\u00f5es.</p> <p></p> <p>Pay Attention</p> <p>No arquivo '<code>mkdocs.yml</code>, a se\u00e7\u00e3o <code>site_url</code> deve estar configurada corretamente para o seu reposit\u00f3rio. Por exemplo, se o seu reposit\u00f3rio estiver em <code>https://github.com/usuario/repositorio</code>, a se\u00e7\u00e3o <code>site_url</code> deve ser:</p> <pre><code>site_url: https://usuario.github.io/repositorio\n</code></pre> <p>Tamb\u00e9m, certifique-se de que a se\u00e7\u00e3o <code>repo_url</code> esteja configurada corretamente para o seu reposit\u00f3rio. Por exemplo:</p> <pre><code>repo_url: https://github.com/usuario/repositorio\n</code></pre>"}]}